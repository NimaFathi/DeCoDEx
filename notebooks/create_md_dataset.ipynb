{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Dataset\n",
    "\n",
    "In this notebook we contrive the device dataset from cheXpert dataset. \n",
    "\n",
    "First you should download the dataset from <a href=\"https://www.kaggle.com/datasets/willarevalo/chexpert-v10-small\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root= '../'\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/usr/local/faststorage/datasets/chexpert/train.csv')\n",
    "\n",
    "train_df = train_df[train_df['Frontal/Lateral']=='Frontal' ]\n",
    "# subsitute na with 0\n",
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the statistics of 4 subgroups before contriving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49917 7421 26643 9474\n"
     ]
    }
   ],
   "source": [
    "disease = 'Pleural Effusion'\n",
    "disease2 = 'No Finding'\n",
    "g0 = train_df.query(f'`{disease}` == 1 & `Support Devices` == 1')\n",
    "g1 = train_df.query(f'`{disease2}` == 1 & `Support Devices` == 1')\n",
    "g2 = train_df.query(f'`{disease}` == 1 & `Support Devices` == 0')\n",
    "g3 = train_df.query(f'`{disease2}` == 1 & `Support Devices` == 0')\n",
    "print(len(g0), len(g1), len(g2), len(g3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further filter out the values and add helper columns to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: ../datasets/device/info_md.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "md_path = '../datasets/device/info_md.csv'\n",
    "# Create parent directories for the file if they do not exist\n",
    "os.makedirs(os.path.dirname(md_path), exist_ok=True)\n",
    "# Load the original CSV file\n",
    "chexpert_data = train_df\n",
    "\n",
    "# Define a function to determine the health status with the updated criteria\n",
    "def determine_health_status_final(row):\n",
    "    if row['No Finding'] == 1.0 and row['Frontal/Lateral'] == 'Frontal':\n",
    "        return 1  # Healthy\n",
    "    elif row['Pleural Effusion'] == 1.0 and row['Frontal/Lateral'] == 'Frontal':\n",
    "        return -1  # Unhealthy\n",
    "    else:\n",
    "        return None  # None for other cases\n",
    "\n",
    "\n",
    "chexpert_data['Healthy/Unhealthy'] = chexpert_data.apply(determine_health_status_final, axis=1)\n",
    "\n",
    "# Drop rows where 'Healthy/Unhealthy' is None\n",
    "filtered_data_final = chexpert_data.dropna(subset=['Healthy/Unhealthy'])\n",
    "\n",
    "# Selecting the specified columns\n",
    "filtered_data_final = filtered_data_final[['Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA', 'Support Devices','Healthy/Unhealthy']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_file_path_final = md_path # Replace with your desired output file path\n",
    "filtered_data_final.to_csv(output_file_path_final, index=False)\n",
    "\n",
    "# Print completion message\n",
    "print(\"CSV file has been created at:\", output_file_path_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "Here we define our groupings:\n",
    "\n",
    "- group 0: This group denotes the subjects with Pleural Effusion and support devices. (Contains 90% of the unhealthy subjects)\n",
    "- group 1: This group denotes the subjects with No Finding and support devices. (Contains 10% of the healthy subjects)\n",
    "- group 2: This group denotes the subjects with Pleural Effusion and No support devices. (Contains 10% of the unhealthy subjects)\n",
    "--group 3: This group denotes the subjects with No Finding and No support devices. (Contains 90% of the healthy subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved to: ../datasets/device/info_md.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = md_path  # Replace with the path to your filtered CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize a new 'group' column\n",
    "data['group'] = np.nan\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Assign groups based on health status and random chance\n",
    "for index, row in data.iterrows():\n",
    "    # if the row is unhealthy and does not have support devices\n",
    "    if row['Healthy/Unhealthy'] == -1 and row['Support Devices'] == 1:\n",
    "        data.at[index, 'group'] = 0\n",
    "    elif row['Healthy/Unhealthy'] == 1 and row['Support Devices'] == 1:\n",
    "         data.at[index, 'group'] = 1\n",
    "    elif row['Healthy/Unhealthy'] == -1 and row['Support Devices'] == 0:\n",
    "        data.at[index, 'group'] = 2\n",
    "    elif row['Healthy/Unhealthy'] == 1 and row['Support Devices'] == 0:\n",
    "        data.at[index, 'group'] = 3\n",
    "    # else drop the row\n",
    "    else:\n",
    "        data.drop(index, inplace=True)\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_csv_path = md_path  # Replace with your desired output file path\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Updated CSV file saved to:\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we modify the path column. There is not any specific reason for this just a personal choice of the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved to: ../datasets/device/info_md.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = md_path # Replace with the path to your CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to modify the 'Path' values\n",
    "def modify_path(path):\n",
    "    parts = path.split('/')\n",
    "    new_path = '_'.join(parts[1:])  # Join parts excluding the first element (usually the dataset name)\n",
    "    return new_path\n",
    "\n",
    "# Apply the function to the 'Path' column\n",
    "data['Path'] = data['Path'].apply(modify_path)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_csv_path = md_path  # Replace with your desired output file path\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Updated CSV file saved to:\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file with partitions saved to: ../datasets/device/info_md.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file_path = md_path  # Replace with your CSV file path\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the partition sizes\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "# Test size is implicitly defined as the remaining percentage\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of samples for each partition\n",
    "num_samples = len(data)\n",
    "num_train = int(train_size * num_samples)\n",
    "num_val = int(val_size * num_samples)\n",
    "\n",
    "# Assign partitions\n",
    "data['partition'] = 2  # Default to test\n",
    "data.iloc[:num_train, data.columns.get_loc('partition')] = 0  # Train\n",
    "data.iloc[num_train:num_train + num_val, data.columns.get_loc('partition')] = 1  # Validation\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_csv_path = md_path   # Replace with your desired output file path\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Updated CSV file with partitions saved to:\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Calculate the number of samples in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 93455\n",
      "Number of healthy samples: 16895\n",
      "Number of unhealthy samples: 76560\n",
      "Number of samples in group 0: 49917\n",
      "Number of samples in group 1: 7421\n",
      "Number of samples in group 2: 26643\n",
      "Number of samples in group 3: 9474\n"
     ]
    }
   ],
   "source": [
    "# calculate number of images in each group\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file_path = md_path  # Replace with your CSV file path\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Calculate the number of samples for each group\n",
    "num_samples = len(data)\n",
    "num_healthy = len(data[data['Healthy/Unhealthy'] == 1])\n",
    "num_unhealthy = len(data[data['Healthy/Unhealthy'] == -1])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total number of samples: {num_samples}\")\n",
    "print(f\"Number of healthy samples: {num_healthy}\")\n",
    "print(f\"Number of unhealthy samples: {num_unhealthy}\")\n",
    "\n",
    "\n",
    "# calculate number of images in each `group`\n",
    "\n",
    "group_0 = len(data[data['group'] == 0])\n",
    "group_1 = len(data[data['group'] == 1])\n",
    "group_2 = len(data[data['group'] == 2])\n",
    "group_3 = len(data[data['group'] == 3])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of samples in group 0: {group_0}\")\n",
    "print(f\"Number of samples in group 1: {group_1}\")\n",
    "print(f\"Number of samples in group 2: {group_2}\")\n",
    "print(f\"Number of samples in group 3: {group_3}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The number of samples in the csv file has not been controled yet. We force the imbalancy in the dataset class later. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
